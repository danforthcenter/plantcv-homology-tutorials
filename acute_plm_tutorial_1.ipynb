{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9136e1fa",
   "metadata": {},
   "source": [
    "# Exercise 1: Overview of the Acute pseudo-landmarking\n",
    "This is an introduction to the pseudo-landmarking method based around the `acute` function found within PlantCV. This tool is designed for morphometric analysis, which due to its relative simplicity, can easily scale between different datasets in order to capture informative shape data in the form of de novo landmarks.  This notebook serves as demonstration of the image data curration required by acute and also documents the initial outputs of `acute` which can be used either to optimize this workflow. Later exercises will build off of what is covered within this document in order to show the potential of this method to end users. To begin, let's start by loading the modules we'll need and then take stock of the acute function and how it operates by running help to see what inputs it requires..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de59dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from plantcv import plantcv as pcv\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c93b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PlantCV adjustable global parameters\n",
    "pcv.params.debug = \"plot\"\n",
    "pcv.params.text_size = 20\n",
    "pcv.params.text_thickness = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc64210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function acute in module plantcv.plantcv.homology.acute:\n",
      "\n",
      "acute(obj, mask, win, threshold)\n",
      "    Identify landmark positions within a contour for morphometric analysis\n",
      "    \n",
      "    Inputs:\n",
      "    obj         = An opencv contour array of interest to be scanned for landmarks\n",
      "    mask        = binary mask used to generate contour array (necessary for ptvals)\n",
      "    win         = maximum cumulative pixel distance window for calculating angle\n",
      "                  score; 1 cm in pixels often works well\n",
      "    threshold   = angle score threshold to be applied for mapping out landmark\n",
      "                  coordinate clusters within each contour\n",
      "    \n",
      "    Outputs:\n",
      "    homolog_pts = pseudo-landmarks selected from each landmark cluster\n",
      "    start_pts   = pseudo-landmark island starting position; useful in parsing homolog_pts in downstream analyses\n",
      "    stop_pts    = pseudo-landmark island end position ; useful in parsing homolog_pts in downstream analyses\n",
      "    ptvals      = average values of pixel intensity from the mask used to generate cont;\n",
      "                  useful in parsing homolog_pts in downstream analyses\n",
      "    chain       = raw angle scores for entire contour, used to visualize landmark\n",
      "                  clusters\n",
      "    verbose_out = supplemental file which stores coordinates, distance from\n",
      "                  landmark cluster edges, and angle score for entire contour.  Used\n",
      "                  in troubleshooting.\n",
      "    \n",
      "    :param obj: numpy.ndarray\n",
      "    :param mask: numpy.ndarray\n",
      "    :param win: int\n",
      "    :param threshold: int\n",
      "    :return homolog_pts:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pcv.homology.acute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a312c",
   "metadata": {},
   "source": [
    "# Required image input variables\n",
    "\n",
    "We'll need 4 variables for each image we run.  Two are derived from the image itself, a contour array representing the outline of a plants image mask (obj) and the image mask itself which is used for output purposes (mask). \n",
    "\n",
    "Let's first start by creating these first two objects. To begin, let's load our first image from a time series sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd1e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7618bd87f048b082e6cb86d93df94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "day = 10\n",
    "path = \"./imgs\"\n",
    "name = f\"B100_rep1_d{day}\"\n",
    "# Read the image from a file\n",
    "img, imgpath, imgname = pcv.readimage(filename=os.path.join(path, name + \".jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35989428",
   "metadata": {},
   "source": [
    "# Reviewing our loaded image\n",
    "\n",
    "From what we can see, the plant is on a mostly homogeneous white background. It should be relatively easy to use the color channel differences to threshold the pixels representing our plant from the rest of the image to create our mask.  To begin let's take a look at the color channels to see which will be the most useful.\n",
    "\n",
    "In comparing the 'Lab' and 'HSV' color spaces it appears there's a bit more contrast to work within the HSV space, but that soil near the stage for the pot could be a problem.  With that in mind the 'Lab' color space is our best bet. Let's take a look at which individual channels are the most informative..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d79cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99d129238a54573b3cfb57134e399e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot all Lab and HSV color channels\n",
    "cs = pcv.visualize.colorspaces(rgb_img=img, original_img=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba7b4b",
   "metadata": {},
   "source": [
    "# Binary thresholding\n",
    "\n",
    "The 'L' channel unfortunately doesn't appear to help very much in denoting the plant pixels from the background.  However, there's good signal in the 'a' channel (darker pixels) and the 'b' channel (brighter pixels) so using a conjunction of these two grayscale images should give us a reasonable mask to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346cbafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34c8968796f460496ea22e5535a97cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the RGB image to Lab and extract the \"a\" channel\n",
    "img_a = pcv.rgb2gray_lab(rgb_img=img, channel=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba2aa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15125dfe96074b9da423afeaecfbf958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the RGB image to Lab and extract the \"b\" channel\n",
    "img_b = pcv.rgb2gray_lab(rgb_img=img, channel=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359712bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53e788757dd45e4bc3dd3ecc7a57c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply a binary threshold to the \"a\" channel grayscale image\n",
    "mask_a = pcv.threshold.binary(gray_img=img_a, threshold=123, max_value=255, object_type=\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd8e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6055c9c4608b4114a3e4386b18555595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply a binary threshold to the \"b\" channel grayscale image\n",
    "mask_b = pcv.threshold.binary(gray_img=img_b, threshold=133, max_value=255, object_type=\"light\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8929e192",
   "metadata": {},
   "source": [
    "# Merging binary thresholds into our mask\n",
    "\n",
    "In both cases we have a few stray pixels (more so in mask a), but we're certainly on the right track! Now lets go ahead and identify which pixels these thresholds can agree on keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62c1d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedb1bce38204f7eac722c719f99295a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge the two binary masks where the pixels are white in both a AND b\n",
    "mask = pcv.logical_and(bin_img1=mask_a, bin_img2=mask_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a55807",
   "metadata": {},
   "source": [
    "# Extracting the plant contours\n",
    "\n",
    "Now with our merged mask defining the shape our our plant we can extract our contour to use for pseudo-landmark identification. This will be done through the use of the `plantcv.find_objects` function where the contours and a tree hierarchy of contours will be extracted as well (important for images in which internal volumes resulting from crossovers between structures occurs). \n",
    "\n",
    "Although not necessary yet in this demonstration the steps below demonstration how the plants outer contour is defined based on which bears the largest volume. Contours contained within this 'parent' contour are then stored as well for downstream analysis within a contour list. This will effectively exclude other components of the mask unrelated to our plant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67286110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24d7ad841214d3b8d509283077e8426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify the contours and contour structure (hierarchy) of the plant\n",
    "cnt, cnt_str = pcv.find_objects(img=img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b648722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d730eb07f2493795bd4c2060f0102a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a region of interest (ROI) that encompasses the plant area\n",
    "roi, roi_str = pcv.roi.rectangle(img=img, x=500, y=500, h=1100, w=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26fe6f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df65e25219b1415f879fbd6bd1c48291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38690907b274e00b2326909a5430eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter the contours using the ROI and return the largest contour and the secondary contours to it\n",
    "kept_cnt, kept_str, kept_mask, kept_area = pcv.roi_objects(img=img, roi_contour=roi, roi_hierarchy=roi_str, object_contour=cnt, obj_hierarchy=cnt_str, roi_type=\"largest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f140f",
   "metadata": {},
   "source": [
    "# Acute pseudo-landmark identification\n",
    "\n",
    "Now that we have our contours we can come back to the previous two input parameters of `acute` which we have thus far ignored but are key to its functionality.  `acute` operates using a modified form of chain-coding akin to a navigators compass taking steps along a contour and within a local window two bounding points on either side of this window are defined from which an angle score can be calculated for the vertex of the 3 points.  The size of this local window is defined as a pixel distance using the `win` variable.  Following the calculation of this angle score it is then weighed against a threshold that is stored in our last variable `thresh` allowing for features of interest to be defined de novo.  Given that acute regions are often areas of interest for morphometric analysis setting this threshold to maximize the 'acuteness' of the contour serves to provide a relatively simple way to identify pseudo-landmarks. \n",
    "\n",
    "When specifying `win` it is often best to select a value which is at least half the distance of the smallest feature in the plant that is deemed relevant.  In the case of Setaria which we are using in this demonstration the first leaf is usually 2 cm long so selecting a window size <=1 cm is optimal to prevent conflict between adjacent landmarks along the contour.\n",
    "\n",
    "When specifying `threshold` the best practice is to leave this value at 90 given in order to identify acute regions. However, to provide downstream flexibility this parameter has the capacity to use other user defined values in case more stringent or lax thresholds are required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbee3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 25\n",
    "thresh = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841609d8",
   "metadata": {},
   "source": [
    "# Running acute in debugging mode\n",
    "\n",
    "As is standard with other PlantCV modules, `acute` is built with debugging features that produces verbose outputs for the sake of troubleshooting. Given this is our first attempt at running this function lets go ahead and run it with debugging enabled to see what these outputs are... \n",
    "\n",
    "Note: while iterating through the contour list isn't necessary for a single outline as we have here this step is invaluable in later stages where volumes internal to our plant outline are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b628248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour volume: 2184.140382528305\n",
      "Fusing contour edges\n",
      "route C\n",
      "Landmark site: 1841, Start site: 1819, Term. site: 21\n",
      "Landmark point indices: [1841]\n",
      "Starting site indices: [1819]\n",
      "Termination site indices: [21]\n",
      "route C\n",
      "Landmark site: 308, Start site: 284, Term. site: 333\n",
      "Landmark point indices: [1841, 308]\n",
      "Starting site indices: [1819, 284]\n",
      "Termination site indices: [21, 333]\n",
      "route C\n",
      "Landmark site: 553, Start site: 528, Term. site: 577\n",
      "Landmark point indices: [1841, 308, 553]\n",
      "Starting site indices: [1819, 284, 528]\n",
      "Termination site indices: [21, 333, 577]\n",
      "route C\n",
      "Landmark site: 883, Start site: 869, Term. site: 894\n",
      "Landmark point indices: [1841, 308, 553, 883]\n",
      "Starting site indices: [1819, 284, 528, 869]\n",
      "Termination site indices: [21, 333, 577, 894]\n",
      "route C\n",
      "Landmark site: 976, Start site: 948, Term. site: 1001\n",
      "Landmark point indices: [1841, 308, 553, 883, 976]\n",
      "Starting site indices: [1819, 284, 528, 869, 948]\n",
      "Termination site indices: [21, 333, 577, 894, 1001]\n",
      "route C\n",
      "Landmark site: 1110, Start site: 1080, Term. site: 1137\n",
      "Landmark point indices: [1841, 308, 553, 883, 976, 1110]\n",
      "Starting site indices: [1819, 284, 528, 869, 948, 1080]\n",
      "Termination site indices: [21, 333, 577, 894, 1001, 1137]\n",
      "route C\n",
      "Landmark site: 1334, Start site: 1310, Term. site: 1359\n",
      "Landmark point indices: [1841, 308, 553, 883, 976, 1110, 1334]\n",
      "Starting site indices: [1819, 284, 528, 869, 948, 1080, 1310]\n",
      "Termination site indices: [21, 333, 577, 894, 1001, 1137, 1359]\n",
      "route C\n",
      "Landmark site: 1476, Start site: 1454, Term. site: 1502\n",
      "Landmark point indices: [1841, 308, 553, 883, 976, 1110, 1334, 1476]\n",
      "Starting site indices: [1819, 284, 528, 869, 948, 1080, 1310, 1454]\n",
      "Termination site indices: [21, 333, 577, 894, 1001, 1137, 1359, 1502]\n",
      "    landmark number: 8\n"
     ]
    }
   ],
   "source": [
    "landmark_output=[]\n",
    "acute_mask = np.copy(img)\n",
    "for cont in kept_cnt:\n",
    "    if cv2.arcLength(cont,True) > 2*win:\n",
    "        print('Contour volume: '+str(cv2.arcLength(cont, True)))\n",
    "\n",
    "        cv2.drawContours(acute_mask, cont, -1, (128,0,0), 3)\n",
    "        homolog_pts, homolog_start, homolog_stop, homolog_cc, chain, max_dist = pcv.homology.acute(obj=cont, mask=mask, win=win, threshold=thresh)\n",
    "        cv2.drawContours(acute_mask, homolog_pts, -1, (0,0,255), 3)\n",
    "        print('    ' + 'landmark number: ' + str(len(homolog_pts)))\n",
    "\n",
    "        for h in range(0, len(homolog_pts)):\n",
    "            landmark_output.append([name, homolog_pts[h][0][0], homolog_pts[h][0][1], homolog_start[h][0][0], homolog_start[h][0][1], homolog_stop[h][0][0], homolog_stop[h][0][1], homolog_cc[h],])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8ffefec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920afb2333a24a5ca9e35092ce6911b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pcv.plot_image(acute_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32731e85",
   "metadata": {},
   "source": [
    "# Acute angle score chain-code output\n",
    "\n",
    "We did quite a bit of work just above so let's go ahead and try to break it down item by item.  To start we successfully ran `acute` which used its chain coding based scoring method to identify landmarks (8 in this example).  However, we started with several hundred vertices comprising our outline (the purple dots we saw earlier) so how did we reduce those down to 8 pseudo-landmarks!? \n",
    "\n",
    "`acute` actually undergoes an extra step beyond simply calculating angle scores in that it attempts to identify 'islands' of acute points and upon finding these regions it approximates the best mid point of each location within the contour. Let's have a look at our contour described by it's acute angle scores...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66b084e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2025957d8440e8a1de181389fab620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain_pos=range(0, len(chain))\n",
    "\n",
    "fig, (fig1, fig2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "#Plot results\n",
    "fig1.plot(chain_pos, chain, color='black')\n",
    "fig1.axhline(y=thresh, color='r', linestyle='-')\n",
    "fig1.set_title('Angle scores by position')\n",
    "\n",
    "fig2.hist(chain, color='black')\n",
    "fig2.axvline(x=thresh, color='r', linestyle='-')\n",
    "fig2.set_title('Angle score histogram')\n",
    "\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcca62",
   "metadata": {},
   "source": [
    "If we focus on our first graph on the left the black line representing the individual acute angle scores of each vertex along our contour outline we can see there definitely seems to be a waveform that quickly decays to zero as we hit each acute island. It's also probably apparent we're actually splitting these islands in half at either end of our chain in linearizing this output.  The 'Fusing contour edges' step `acute` does automatically (appeared in the output panel) is performed to remedy mistaking these two segments as different regions. \n",
    "\n",
    "When we compare these regions to our threshold (the red line) it becomes clear these 'waves' correspond to our landmarks.  If we felt a particular need to optimize this threshold since we should optimally have a bimodal output a histogram of the angle scores can be generated as shown on the right to train this threshold in order to better optimize signal.\n",
    "\n",
    "Now that we have a general idea of how `acute` is determining its primary outputs let's see how they compare to our original image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1553a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2681d65983ea4dbd96b32bf303d6b6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_plms = img.copy()\n",
    "\n",
    "for c in kept_cnt:\n",
    "    cv2.drawContours(img_plms, homolog_pts, -1, (255, 255, 255), 14)    \n",
    "\n",
    "#Plot results\n",
    "plm_fig=plt.figure(figsize=(7, 10))\n",
    "plm_fig=plt.imshow(img_plms)\n",
    "plm_fig=plt.xscale('linear')\n",
    "plm_fig=plt.axis('off')\n",
    "plm_fig=plt.title('B100 day '+str(day))\n",
    "plt.show(plm_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b50f2",
   "metadata": {},
   "source": [
    "In viewing our plms plotted in white while looking back on our original image we used for this exercise we can see that not only were we able to clearly define regions of interest using a threshold on our angle score waveforms but these do in fact appear to correlate with regions of interest for morphometric analysis such as the tips of leaves as well as the ligules where the base of each leaf attaches to the culm (the grass equivalent to a stem).  This is the basis by which `acute` functions and serves as the basic mode of operation for this workflow.  In the next exercise 2 we will expand on this knowledge by learning to interact with and store time series data which in exercise 3 can subsequently be fused together into homology groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c72de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97a7103506a52a095f5ce50d4e6705610ae1ba7ea83acc6ada7fa062b45c97ba"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
