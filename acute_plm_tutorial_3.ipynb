{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1f9407",
   "metadata": {},
   "source": [
    "# Exercise 3: Generating homology groups from pseudo-landmark data\n",
    "\n",
    "In this third exercise we will review one of the downstream applications of our batch plm data we generated in our previous exercise by generating de novo homology groups.  It should be noted that this method, while incredibly powerful, has some prior assumptions in its usage.  To drive home the point, THIS METHOD IS DESIGNED TO ESTIMATE GROUPS BY MAKING ASSUMPTIONS ABOUT BIOLOGICAL HOMOLOGY (i.e. not persistent homology which is an completely different analytical method!).\n",
    "\n",
    "Ideally, when image data of sufficient quality is presented to this workflow homology groups could even be inferred to be orthologous to one another although, similar to (phylo)genetic clustering methods, you get out what you put in and so this may be subjective based on your dataset.  That being said, there are concievably two datasets where this homology grouping set is applicable:\n",
    "\n",
    "1) Linking landmarks through time series image data to survey growth and development of independent structures through time.\n",
    "\n",
    "2) Linking landmarks between comparable static materials either between individuals or genotypes for comparing variability of these landmarks in analogous organismal datasets (i.e. leaves with readily apparent lobes, awns, or sinuses, as one example).\n",
    "\n",
    "Given our homology grouping workflow was designed for the former dataset we will work through a demonstration of how this works and how best to go about performing this analysis in an idealized dataset.  Let's get started by importing what we need...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc1b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from plantcv import plantcv as pcv\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212c6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PlantCV adjustable global parameters\n",
    "pcv.params.debug = \"plot\"\n",
    "pcv.params.text_size = 20\n",
    "pcv.params.text_thickness = 10\n",
    "pcv.params.line_thickness = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3428f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 25\n",
    "thresh = 90\n",
    "\n",
    "path = './imgs'\n",
    "days = range(10, 14)\n",
    "name_prefix = 'B100_rep1_d'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b861ddd",
   "metadata": {},
   "source": [
    "Before we get rolling though we'll have you enter in a output file path to save some graphs this workflow will generate which will be appended to our output prefix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38810a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = './output'\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "outfile_prefix = os.path.join(outpath, 'B100_d10_d11_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0dd80",
   "metadata": {},
   "source": [
    "Now that we have what we need to rerun the script we walked through in the previous exercise let's run through the code block we covered last time (with a few modifications to the outputs) and then think about how best to move forward with our landmark outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3715c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Contour volume: 2184.140382528305\n",
      "Fusing contour edges\n",
      "route C\n",
      "Landmark site: 1841, Start site: 1819, Term. site: 21\n",
      "Landmark point indices: [1841]\n",
      "Starting site indices: [1819]\n",
      "Termination site indices: [21]\n",
      "route C\n",
      "Landmark site: 308, Start site: 284, Term. site: 333\n",
      "Landmark point indices: [1841, 308]\n",
      "Starting site indices: [1819, 284]\n",
      "Termination site indices: [21, 333]\n",
      "route C\n",
      "Landmark site: 553, Start site: 528, Term. site: 577\n",
      "Landmark point indices: [1841, 308, 553]\n",
      "Starting site indices: [1819, 284, 528]\n",
      "Termination site indices: [21, 333, 577]\n",
      "route C\n",
      "Landmark site: 883, Start site: 869, Term. site: 894\n",
      "Landmark point indices: [1841, 308, 553, 883]\n",
      "Starting site indices: [1819, 284, 528, 869]\n",
      "Termination site indices: [21, 333, 577, 894]\n",
      "route C\n",
      "Landmark site: 976, Start site: 948, Term. site: 1001\n",
      "Landmark point indices: [1841, 308, 553, 883, 976]\n",
      "Starting site indices: [1819, 284, 528, 869, 948]\n",
      "Termination site indices: [21, 333, 577, 894, 1001]\n",
      "route C\n",
      "Landmark site: 1110, Start site: 1080, Term. site: 1137\n",
      "Landmark point indices: [1841, 308, 553, 883, 976, 1110]\n",
      "Starting site indices: [1819, 284, 528, 869, 948, 1080]\n",
      "Termination site indices: [21, 333, 577, 894, 1001, 1137]\n",
      "route C\n",
      "Landmark site: 1334, Start site: 1310, Term. site: 1359\n",
      "Landmark point indices: [1841, 308, 553, 883, 976, 1110, 1334]\n",
      "Starting site indices: [1819, 284, 528, 869, 948, 1080, 1310]\n",
      "Termination site indices: [21, 333, 577, 894, 1001, 1137, 1359]\n",
      "route C\n",
      "Landmark site: 1476, Start site: 1454, Term. site: 1502\n",
      "Landmark point indices: [1841, 308, 553, 883, 976, 1110, 1334, 1476]\n",
      "Starting site indices: [1819, 284, 528, 869, 948, 1080, 1310, 1454]\n",
      "Termination site indices: [21, 333, 577, 894, 1001, 1137, 1359, 1502]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4f3e31b26d4bccad74e173b515862b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    landmark number: 8\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Contour volume: 2436.750554203987\n",
      "Fusing contour edges\n",
      "route C\n",
      "Landmark site: 2070, Start site: 2047, Term. site: 18\n",
      "Landmark point indices: [2070]\n",
      "Starting site indices: [2047]\n",
      "Termination site indices: [18]\n",
      "route C\n",
      "Landmark site: 265, Start site: 241, Term. site: 289\n",
      "Landmark point indices: [2070, 265]\n",
      "Starting site indices: [2047, 241]\n",
      "Termination site indices: [18, 289]\n",
      "route C\n",
      "Landmark site: 401, Start site: 377, Term. site: 428\n",
      "Landmark point indices: [2070, 265, 401]\n",
      "Starting site indices: [2047, 241, 377]\n",
      "Termination site indices: [18, 289, 428]\n",
      "route C\n",
      "Landmark site: 598, Start site: 574, Term. site: 620\n",
      "Landmark point indices: [2070, 265, 401, 598]\n",
      "Starting site indices: [2047, 241, 377, 574]\n",
      "Termination site indices: [18, 289, 428, 620]\n",
      "route C\n",
      "Landmark site: 839, Start site: 816, Term. site: 862\n",
      "Landmark point indices: [2070, 265, 401, 598, 839]\n",
      "Starting site indices: [2047, 241, 377, 574, 816]\n",
      "Termination site indices: [18, 289, 428, 620, 862]\n",
      "route C\n",
      "Landmark site: 1159, Start site: 1143, Term. site: 1173\n",
      "Landmark point indices: [2070, 265, 401, 598, 839, 1159]\n",
      "Starting site indices: [2047, 241, 377, 574, 816, 1143]\n",
      "Termination site indices: [18, 289, 428, 620, 862, 1173]\n",
      "route C\n",
      "Landmark site: 1258, Start site: 1228, Term. site: 1282\n",
      "Landmark point indices: [2070, 265, 401, 598, 839, 1159, 1258]\n",
      "Starting site indices: [2047, 241, 377, 574, 816, 1143, 1228]\n",
      "Termination site indices: [18, 289, 428, 620, 862, 1173, 1282]\n",
      "route C\n",
      "Landmark site: 1383, Start site: 1352, Term. site: 1406\n",
      "Landmark point indices: [2070, 265, 401, 598, 839, 1159, 1258, 1383]\n",
      "Starting site indices: [2047, 241, 377, 574, 816, 1143, 1228, 1352]\n",
      "Termination site indices: [18, 289, 428, 620, 862, 1173, 1282, 1406]\n",
      "route C\n",
      "Landmark site: 1581, Start site: 1557, Term. site: 1605\n",
      "Landmark point indices: [2070, 265, 401, 598, 839, 1159, 1258, 1383, 1581]\n",
      "Starting site indices: [2047, 241, 377, 574, 816, 1143, 1228, 1352, 1557]\n",
      "Termination site indices: [18, 289, 428, 620, 862, 1173, 1282, 1406, 1605]\n",
      "route C\n",
      "Landmark site: 1707, Start site: 1692, Term. site: 1724\n",
      "Landmark point indices: [2070, 265, 401, 598, 839, 1159, 1258, 1383, 1581, 1707]\n",
      "Starting site indices: [2047, 241, 377, 574, 816, 1143, 1228, 1352, 1557, 1692]\n",
      "Termination site indices: [18, 289, 428, 620, 862, 1173, 1282, 1406, 1605, 1724]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af33a26f05fd400880343bd44018dd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    landmark number: 10\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Contour volume: 2664.7160643339157\n",
      "Fusing contour edges\n",
      "route C\n",
      "Landmark site: 0, Start site: 2242, Term. site: 21\n",
      "Landmark point indices: [0]\n",
      "Starting site indices: [2242]\n",
      "Termination site indices: [21]\n",
      "route C\n",
      "Landmark site: 280, Start site: 258, Term. site: 303\n",
      "Landmark point indices: [0, 280]\n",
      "Starting site indices: [2242, 258]\n",
      "Termination site indices: [21, 303]\n",
      "route C\n",
      "Landmark site: 494, Start site: 472, Term. site: 519\n",
      "Landmark point indices: [0, 280, 494]\n",
      "Starting site indices: [2242, 258, 472]\n",
      "Termination site indices: [21, 303, 519]\n",
      "route C\n",
      "Landmark site: 773, Start site: 750, Term. site: 799\n",
      "Landmark point indices: [0, 280, 494, 773]\n",
      "Starting site indices: [2242, 258, 472, 750]\n",
      "Termination site indices: [21, 303, 519, 799]\n",
      "route C\n",
      "Landmark site: 1008, Start site: 988, Term. site: 1031\n",
      "Landmark point indices: [0, 280, 494, 773, 1008]\n",
      "Starting site indices: [2242, 258, 472, 750, 988]\n",
      "Termination site indices: [21, 303, 519, 799, 1031]\n",
      "route C\n",
      "Landmark site: 1323, Start site: 1311, Term. site: 1338\n",
      "Landmark point indices: [0, 280, 494, 773, 1008, 1323]\n",
      "Starting site indices: [2242, 258, 472, 750, 988, 1311]\n",
      "Termination site indices: [21, 303, 519, 799, 1031, 1338]\n",
      "route C\n",
      "Landmark site: 1408, Start site: 1383, Term. site: 1431\n",
      "Landmark point indices: [0, 280, 494, 773, 1008, 1323, 1408]\n",
      "Starting site indices: [2242, 258, 472, 750, 988, 1311, 1383]\n",
      "Termination site indices: [21, 303, 519, 799, 1031, 1338, 1431]\n",
      "route C\n",
      "Landmark site: 1517, Start site: 1487, Term. site: 1544\n",
      "Landmark point indices: [0, 280, 494, 773, 1008, 1323, 1408, 1517]\n",
      "Starting site indices: [2242, 258, 472, 750, 988, 1311, 1383, 1487]\n",
      "Termination site indices: [21, 303, 519, 799, 1031, 1338, 1431, 1544]\n",
      "route C\n",
      "Landmark site: 1733, Start site: 1702, Term. site: 1757\n",
      "Landmark point indices: [0, 280, 494, 773, 1008, 1323, 1408, 1517, 1733]\n",
      "Starting site indices: [2242, 258, 472, 750, 988, 1311, 1383, 1487, 1702]\n",
      "Termination site indices: [21, 303, 519, 799, 1031, 1338, 1431, 1544, 1757]\n",
      "route C\n",
      "Landmark site: 1873, Start site: 1856, Term. site: 1888\n",
      "Landmark point indices: [0, 280, 494, 773, 1008, 1323, 1408, 1517, 1733, 1873]\n",
      "Starting site indices: [2242, 258, 472, 750, 988, 1311, 1383, 1487, 1702, 1856]\n",
      "Termination site indices: [21, 303, 519, 799, 1031, 1338, 1431, 1544, 1757, 1888]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacbdc9fb7fe4b0f9163d374bbae9a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    landmark number: 10\n",
      "Warning: roi_type='largest' will only return the largest contour and its immediate children. Other subcontours will be dropped.\n",
      "Contour volume: 2932.647084593773\n",
      "Fusing contour edges\n",
      "route C\n",
      "Landmark site: 0, Start site: 2442, Term. site: 22\n",
      "Landmark point indices: [0]\n",
      "Starting site indices: [2442]\n",
      "Termination site indices: [22]\n",
      "route C\n",
      "Landmark site: 358, Start site: 333, Term. site: 386\n",
      "Landmark point indices: [0, 358]\n",
      "Starting site indices: [2442, 333]\n",
      "Termination site indices: [22, 386]\n",
      "route C\n",
      "Landmark site: 595, Start site: 573, Term. site: 617\n",
      "Landmark point indices: [0, 358, 595]\n",
      "Starting site indices: [2442, 333, 573]\n",
      "Termination site indices: [22, 386, 617]\n",
      "route C\n",
      "Landmark site: 926, Start site: 905, Term. site: 943\n",
      "Landmark point indices: [0, 358, 595, 926]\n",
      "Starting site indices: [2442, 333, 573, 905]\n",
      "Termination site indices: [22, 386, 617, 943]\n",
      "route C\n",
      "Landmark site: 1004, Start site: 978, Term. site: 1027\n",
      "Landmark point indices: [0, 358, 595, 926, 1004]\n",
      "Starting site indices: [2442, 333, 573, 905, 978]\n",
      "Termination site indices: [22, 386, 617, 943, 1027]\n",
      "route C\n",
      "Landmark site: 1110, Start site: 1079, Term. site: 1133\n",
      "Landmark point indices: [0, 358, 595, 926, 1004, 1110]\n",
      "Starting site indices: [2442, 333, 573, 905, 978, 1079]\n",
      "Termination site indices: [22, 386, 617, 943, 1027, 1133]\n",
      "route C\n",
      "Landmark site: 1312, Start site: 1287, Term. site: 1339\n",
      "Landmark point indices: [0, 358, 595, 926, 1004, 1110, 1312]\n",
      "Starting site indices: [2442, 333, 573, 905, 978, 1079, 1287]\n",
      "Termination site indices: [22, 386, 617, 943, 1027, 1133, 1339]\n",
      "route C\n",
      "Landmark site: 1441, Start site: 1426, Term. site: 1458\n",
      "Landmark point indices: [0, 358, 595, 926, 1004, 1110, 1312, 1441]\n",
      "Starting site indices: [2442, 333, 573, 905, 978, 1079, 1287, 1426]\n",
      "Termination site indices: [22, 386, 617, 943, 1027, 1133, 1339, 1458]\n",
      "route C\n",
      "Landmark site: 1857, Start site: 1837, Term. site: 1880\n",
      "Landmark point indices: [0, 358, 595, 926, 1004, 1110, 1312, 1441, 1857]\n",
      "Starting site indices: [2442, 333, 573, 905, 978, 1079, 1287, 1426, 1837]\n",
      "Termination site indices: [22, 386, 617, 943, 1027, 1133, 1339, 1458, 1880]\n",
      "route C\n",
      "Landmark site: 2163, Start site: 2137, Term. site: 2187\n",
      "Landmark point indices: [0, 358, 595, 926, 1004, 1110, 1312, 1441, 1857, 2163]\n",
      "Starting site indices: [2442, 333, 573, 905, 978, 1079, 1287, 1426, 1837, 2137]\n",
      "Termination site indices: [22, 386, 617, 943, 1027, 1133, 1339, 1458, 1880, 2187]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719d6a1dfbe04929b58ac5f772e70b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    landmark number: 10\n"
     ]
    }
   ],
   "source": [
    "landmark_output=[['group', 'plmname', 'filename', 'plm_x', 'plm_y', 'SS_x', 'SS_y', 'TS_x', 'TS_y', 'CC_ratio']]\n",
    "for day in days:\n",
    "    # Turn off debugging outputs for most steps to avoid a huge amount of output\n",
    "    pcv.params.debug = None\n",
    "    # 1. Reading our image into the environment\n",
    "    img, imgpath, imgname = pcv.readimage(filename=os.path.join(path, f\"{name_prefix}{day}.jpg\"))\n",
    "    \n",
    "    # 2. Converting our RGB image into an Lab color space and extract the a and b channels\n",
    "    img_a = pcv.rgb2gray_lab(rgb_img=img, channel=\"a\")\n",
    "    img_b = pcv.rgb2gray_lab(rgb_img=img, channel=\"b\")\n",
    "    \n",
    "    # 3. Thresholding our a and b color channels to create two masks\n",
    "    mask_a = pcv.threshold.binary(gray_img=img_a, threshold=123, max_value=255, object_type=\"dark\")\n",
    "    mask_b = pcv.threshold.binary(gray_img=img_b, threshold=133, max_value=255, object_type=\"light\")\n",
    "    \n",
    "    # 4. Merging our individual a and b thresholded masks\n",
    "    mask = pcv.logical_and(bin_img1=mask_a, bin_img2=mask_b)\n",
    "    \n",
    "    # 5. Extracting our contours from the final mask\n",
    "    cnt, cnt_str = pcv.find_objects(img=img, mask=mask)\n",
    "    \n",
    "    # 6. Find largest contour of subject (outer boundary of subject)\n",
    "    roi, roi_str = pcv.roi.rectangle(img=img, x=500, y=500, h=1100, w=800)\n",
    "    kept_cnt, kept_str, kept_mask, kept_area = pcv.roi_objects(img=img, roi_contour=roi, roi_hierarchy=roi_str, \n",
    "                                                               object_contour=cnt, obj_hierarchy=cnt_str, roi_type=\"largest\")\n",
    "    \n",
    "    # 7. Extracting pseudo-landmarks from the plant contours\n",
    "    plt_img = np.copy(img)\n",
    "    for cont in kept_cnt:\n",
    "        if cv2.arcLength(cont, True) > 2*win:\n",
    "            print(f'Contour volume: {cv2.arcLength(cont, True)}')\n",
    "            # Turn debugging back on for acute\n",
    "            pcv.params.debug = \"plot\"\n",
    "            homolog_pts, homolog_start, homolog_stop, homolog_cc, chain, verbose = pcv.homology.acute(img=img, obj=cont, mask=mask,\n",
    "                                                                                                      win=win, threshold=thresh)\n",
    "            print(f'    landmark number: {len(homolog_pts)}')\n",
    "\n",
    "            for h in range(0, len(homolog_pts)):\n",
    "                landmark_output.append([None, f\"{name_prefix}{day}_plm{h+1}\", f\"{name_prefix}{day}\", homolog_pts[h][0][0], homolog_pts[h][0][1], \n",
    "                                        homolog_start[h][0][0], homolog_start[h][0][1], homolog_stop[h][0][0], homolog_stop[h][0][1], homolog_cc[h],])\n",
    "\n",
    "# Convert out output to a pandas dataframe for ease of use hereafter...\n",
    "landmark_pandas = pd.DataFrame(landmark_output[1:len(landmark_output)], columns=landmark_output[0][0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d2bb6",
   "metadata": {},
   "source": [
    "Now that we have our analyses run again let's have another look at data to think about how we'll proceed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e263384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>plmname</th>\n",
       "      <th>filename</th>\n",
       "      <th>plm_x</th>\n",
       "      <th>plm_y</th>\n",
       "      <th>SS_x</th>\n",
       "      <th>SS_y</th>\n",
       "      <th>TS_x</th>\n",
       "      <th>TS_y</th>\n",
       "      <th>CC_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>B100_rep1_d10_plm1</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>901</td>\n",
       "      <td>1151</td>\n",
       "      <td>892</td>\n",
       "      <td>1173</td>\n",
       "      <td>885</td>\n",
       "      <td>1167</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>B100_rep1_d10_plm2</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>787</td>\n",
       "      <td>1425</td>\n",
       "      <td>789</td>\n",
       "      <td>1401</td>\n",
       "      <td>773</td>\n",
       "      <td>1405</td>\n",
       "      <td>6.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>B100_rep1_d10_plm3</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>571</td>\n",
       "      <td>1344</td>\n",
       "      <td>594</td>\n",
       "      <td>1338</td>\n",
       "      <td>595</td>\n",
       "      <td>1342</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>B100_rep1_d10_plm4</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>793</td>\n",
       "      <td>1523</td>\n",
       "      <td>796</td>\n",
       "      <td>1511</td>\n",
       "      <td>783</td>\n",
       "      <td>1519</td>\n",
       "      <td>18.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>B100_rep1_d10_plm5</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>712</td>\n",
       "      <td>1511</td>\n",
       "      <td>736</td>\n",
       "      <td>1508</td>\n",
       "      <td>736</td>\n",
       "      <td>1512</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group             plmname       filename  plm_x  plm_y  SS_x  SS_y  TS_x  \\\n",
       "0  None  B100_rep1_d10_plm1  B100_rep1_d10    901   1151   892  1173   885   \n",
       "1  None  B100_rep1_d10_plm2  B100_rep1_d10    787   1425   789  1401   773   \n",
       "2  None  B100_rep1_d10_plm3  B100_rep1_d10    571   1344   594  1338   595   \n",
       "3  None  B100_rep1_d10_plm4  B100_rep1_d10    793   1523   796  1511   783   \n",
       "4  None  B100_rep1_d10_plm5  B100_rep1_d10    712   1511   736  1508   736   \n",
       "\n",
       "   TS_y    CC_ratio  \n",
       "0  1167  255.000000  \n",
       "1  1405    6.219512  \n",
       "2  1342  255.000000  \n",
       "3  1519   18.888889  \n",
       "4  1512  255.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c679851",
   "metadata": {},
   "source": [
    "Thus far, we've largely been considering this data as a table where we really only cared about our X-Y coordinates that describe our plms. However, when we think about this matrix beyond the the filename and plm x/y columns we can see that we really have quite a few extra dimensions which add some context to our data.  These added dimensions were originally deemed to be potentially useful for generating a rich multivariate dataset to to pull these plms together into homology groups.  `space` no longer is seen as a required component of this pipeline, however, given that analyses seem to only produce negligibly better results with it's inclusion.  That being said, this approach does produce some novel types of metadata which could have alternative applications so we'll at least discuss what `space` is doing here in it's original context, even if we gloss over it in tutorial 4. You may have also noticed we now have a new empty column we've added that didn't exist before called 'group' but for now we'll just ignore it. \n",
    "\n",
    "To begin, let's take our initial outputs from Acute and expand them into our expanded multivariate space to use for homology grouping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e869e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  group             plmname       filename  plm_x  plm_y  SS_x  SS_y  TS_x  \\\n",
      "0  None  B100_rep1_d10_plm1  B100_rep1_d10    901   1151   892  1173   885   \n",
      "1  None  B100_rep1_d10_plm2  B100_rep1_d10    787   1425   789  1401   773   \n",
      "2  None  B100_rep1_d10_plm3  B100_rep1_d10    571   1344   594  1338   595   \n",
      "3  None  B100_rep1_d10_plm4  B100_rep1_d10    793   1523   796  1511   783   \n",
      "4  None  B100_rep1_d10_plm5  B100_rep1_d10    712   1511   736  1508   736   \n",
      "\n",
      "   TS_y    CC_ratio  bot_left_dist  bot_right_dist  top_left_dist  \\\n",
      "0  1167  255.000000     521.647390      404.545424     331.185748   \n",
      "1  1405    6.219512     252.103153      187.416648     371.295031   \n",
      "2  1342  255.000000     211.000000      409.538765     221.000000   \n",
      "3  1519   18.888889     224.294449      132.909744     457.475682   \n",
      "4  1512  255.000000     147.705789      214.560015     412.825629   \n",
      "\n",
      "   top_right_dist  centroid_dist  orientation  centroid_orientation  \n",
      "0       35.000000     284.613773  -146.659293            155.506063  \n",
      "1      330.800544      15.524175   -15.255119             14.931417  \n",
      "2      414.779459     222.036033    99.659893            -72.707551  \n",
      "3      420.286807     113.441615   -23.629378              5.057249  \n",
      "4      441.184769     123.458495    92.385944           -144.893921  \n"
     ]
    }
   ],
   "source": [
    "day = 10\n",
    "group_iter = 1\n",
    "\n",
    "filenames = landmark_pandas.loc[:,['filename']].values\n",
    "cur_plms = landmark_pandas[filenames==name_prefix+str(day)]\n",
    "cur_plms = cur_plms.append(landmark_pandas[filenames==name_prefix+str(day+1)])\n",
    "\n",
    "cur_plms = pcv.homology.space(cur_plms, include_bound_dist=True, include_centroid_dist=True, include_orient_angles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1f01b",
   "metadata": {},
   "source": [
    "Now as we look at our outputs from the `space` function we can see that there is clearly quite a bit of extra information we've just added. Let's breakdown what each of these new elements are item by item just to understand what new information we've generated.  \n",
    "\n",
    "To begin we can consider five distance elements, 'bot_left_dist', 'bot_right_dist', 'top_left_dist', 'top_right_dist', and 'centroid_dist'.  These new values are distances between the plms representing each row and the bounding box corners capturing our current image pairs plms. In addition, we also calculate a centroid point for our current image pair to generate a distance from the 'center of gravity' for these paired plms.  Given we've largely focused on spatial positions alone distance measures, while analogous in terms of being pixel measures, help by giving us some added indication as to where in space our landmarks fall compared to one another.  \n",
    "\n",
    "Beyond these distance measures we have two other elements, 'orientation' and 'centroid_orientation'.  As could be anticipated from these names these elements are both providing some additional information about the direction of the plms in space as opposed to raw distance measures, however, they are accomplishing this in very different ways.  The 'orientation' measures are based purely on the plm, SS, TS coordinates in which the midpoint between SS and TS are calculated and this midpoint is then used to drive a line towards the plm to generate a slope. Following the generation of a slope an angle can be generated using the formula:\n",
    "   \n",
    "    angle = arctan(slope)*(180/pi)\n",
    "\n",
    "By contrast, the 'centroid_orientation' begins at the centroid and drives a line towards the plm to generate a slope then uses a similar formula to what was described above in order to calculate an angle of orientation.  \n",
    "\n",
    "Now that we have a multivariate dataset that is rich in context for comparisons to be made we can begin to determine how similar or distant they are to one another through time. For the initial steps we will use two approaches, PCA which is extremely useful in maximizing the amount of variation while reducing dimensionality (key in a dataset such as ours) followed by clustering approaches used to link nearest neighbors (which will help us stitch our plms together through time).\n",
    "\n",
    "Let's begin with our PCA approach which will be found within our `starscape` function...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c1196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:  [7.64297273 4.79923162 1.56909281 0.33569542] \n",
      "\n",
      "\n",
      "Var. Explained:  [0.51559737 0.32375769 0.1058515  0.02264612] \n",
      "\n",
      "\n",
      "Cumul. Var. Explained:  [0.51559737 0.83935506 0.94520655 0.96785267] \n",
      "\n",
      "\n",
      "3  components sufficiently informative\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d253ad423fe4db9919504bd546d53d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d0c02163ee483589edc7827dca80e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groupA = f\"{name_prefix}{day}\"\n",
    "groupB = f\"{name_prefix}{day+1}\"\n",
    "finalDf, eigvals, loadings = pcv.homology.starscape(cur_plms, groupA, groupB, outfile_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f360cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plmname</th>\n",
       "      <th>filename</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B100_rep1_d10_plm1</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>679.414040</td>\n",
       "      <td>-71.488066</td>\n",
       "      <td>-34.624416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B100_rep1_d10_plm2</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>-62.215929</td>\n",
       "      <td>-55.052674</td>\n",
       "      <td>153.806037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B100_rep1_d10_plm3</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>14.256346</td>\n",
       "      <td>475.918362</td>\n",
       "      <td>-30.316153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B100_rep1_d10_plm4</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>-237.327344</td>\n",
       "      <td>-127.302125</td>\n",
       "      <td>38.876346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B100_rep1_d10_plm5</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>-274.667223</td>\n",
       "      <td>120.381513</td>\n",
       "      <td>-126.398386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              plmname       filename         PC1         PC2         PC3\n",
       "0  B100_rep1_d10_plm1  B100_rep1_d10  679.414040  -71.488066  -34.624416\n",
       "1  B100_rep1_d10_plm2  B100_rep1_d10  -62.215929  -55.052674  153.806037\n",
       "2  B100_rep1_d10_plm3  B100_rep1_d10   14.256346  475.918362  -30.316153\n",
       "3  B100_rep1_d10_plm4  B100_rep1_d10 -237.327344 -127.302125   38.876346\n",
       "4  B100_rep1_d10_plm5  B100_rep1_d10 -274.667223  120.381513 -126.398386"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d18749",
   "metadata": {},
   "source": [
    "Using the StarScape function above a principal component analysis is undertaken to reduce the dimensionality of our multivariate space to a minimal number of maximally informative dimensions (3 in this example) while also providing some helpful outputs for consideration as we perform our later homology grouping with Constella.  When running StarScape in debugging mode as we have it should be noted that various attributes of the PCA which was performed such as the eigenvalues and eigenvectors will be printed as outputs.\n",
    "\n",
    "The first of the graphical outputs that StarScape produces is a scree plot.  The eigenvalues plotted in this graph are used to dynamically define the number of components required for explaining the relationship of our plms groupings within multivariate space.  As we can observe in this scree plot, as can be expected with most PCA analyses, that the vast majority of our variance can be explained with the first few dimensions which are then stored as an output dataframe. The number of output components can be defined by the user although it is recommended to have a strong reasoning from deviating from the default setting built within this script. \n",
    "\n",
    "Following the identification of our number of informative components we can then observe our 'starscape' as two overlaid scatter plots reflecting the first three PC dimensions.  In this graph we can also observe that our two perspectives in time between this image neighbor pair are color coded allowing us to see that in fact several of these plms appear to be almost perfectly overlapping through time suggesting they likely represent the same structure. This neighbor pair was purposefully chosen for this demonstration as we can see day 11 has 2 points which appear to lack partners.  This is due to the fact that a new leaf was exerted in this frame resulting in two new plms representing a leaf tip and ligule.  \n",
    "\n",
    "This PC space will provide a perfect test case for our demonstrating the methodology of our homology grouping script Constella...  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df21fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 plms to group\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f20cec2e835462c84bbcb0a8c766dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_plms, group_iter = pcv.homology.constella(cur_plms=cur_plms, pc_starscape=finalDf, group_iter=group_iter, outfile_prefix=outfile_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a4e70",
   "metadata": {},
   "source": [
    "Although we initially only see the hierarchical cluster used by Constella shown as a dendrogram graphic quite a bit has actually happened when we ran this function in order to generate our homology groupings!\n",
    "\n",
    "Let's start by thinking about what our hierarchical cluster of our neighboring frames looks like in this graphic.  We can see that for the vast majority of our plms there appear to be paired points which correspond to a plm from each frame (given the 3D plot from our starscape plot this probably isn't much of a surprise!).  Given this initial finding it would almost seem at first glance that focusing on groups consisting of two plms would be sufficient, however, there is some nuance to plm datasets given they are dynamically describing growth as it occurs.  For example, we can see at least one case in which clusters of three plms form within this dendrogram, and another more complex situation in which day 11 plm 2 becomes a rogue point in the proximity of a pair of homology groups.  In each of these cases one of the emergent plms that just appeared in the day 11 frame is clustering around its nearest cluster pair in the starscape output.  Even when they are no longer emergent it is often common for these new points to rapidly migrate for several days before reaching stationarity as the structure they represent grows and eventually arrests its development.  As such we need a fairly robust means of describing structures which are more or less non-moving while also being able to dynamically characterize noisier subcomponents of the dataset which may be undertaking fairly rapid change for a transient period of time.  Ultimately Constella is designed around the concept for describing groups as duets which are adjacent to one another in time.  Let's use a series of examples to grasp this concept:\n",
    "\n",
    "## Constella homology grouping example (i.e. identifying duets, quartets, and rogues)\n",
    "\n",
    "1)\n",
    "                                        \n",
    "                     --- Day 11 Group 1   |   As we look at this initial illustration of a dendrogram it is clear\n",
    "    ----------------|                     |   that there is a clear group which we refer to as a 'duet' which will\n",
    "                     --- Day 12 Group 1   |   share a group ID serial number during Constella de novo assignment.\n",
    "\n",
    "2)\n",
    "\n",
    "                     --- Day 11 Group 1   |  As development continues things often become more complicated with\n",
    "                ----|                     |  novel structures begin to appear and lacking partners due to their \n",
    "               |     --- Day 12 Group 1   |  recent appearance they often cluster around a known duet. These \n",
    "    -----------|                          |  points which appear to lack any notable partner to pair with are\n",
    "                -------- Day 12 Group 2   |  referred to as rogues and are often given their own group ID number.\n",
    "                \n",
    "3) \n",
    "\n",
    "                     --- Day 12 Group 1   |  Development continues and further evidence begins to accumuluate for \n",
    "                ----|                     |  group 2 with a partner now appearing in day 13.  However, when growth\n",
    "               |     --- Day 13 Group 1   |  is rapidly occuring duets sometimes have difficulty manifesting due \n",
    "             --|                          |  to rapid changes between day 12 and 13 for group 2. This leads to a\n",
    "            |  |                          |  grade luck structure as shown here we refer to as a quartet which is\n",
    "    --------|   -------- Day 12 Group 2   |  merely an artifact of a similar problem known as 'long branch attract\n",
    "            |                             |  -ion' in phylyogenetics. So long as a grade of 2 plms exactly can be\n",
    "             ----------- Day 13 Group 2   |  resolved a quartet can be used to assign the identity of group 2.\n",
    "\n",
    "4)\n",
    "\n",
    "                     --- Day 13 Group 1   |  As development continues and the rapid growth that gave rise to the   \n",
    "         -----------|                     |  quartet structure abates we can begin to clearly resolve duets for\n",
    "        |            --- Day 14 Group 1   |  groups 1 and 2.  These structured duets often make up the bulk of \n",
    "    ----|                                 |  our dendrogram results as shown above which, like figure (1) can \n",
    "        |        ------- Day 13 Group 2   |  readily be used to assign group identities to duets.\n",
    "         -------|\n",
    "                 ------- Day 14 Group 2\n",
    "                     \n",
    "In the manner described above, Constella operates through iteratively assigning points identities through an expanding nearest neighbor homology grouping scheme which is superfically similar to neighbor joining.  Although these steps are critical to defining how Constella weighs homology, as important is how Constella chooses to define new serial number identities vs. perserving existing ones:  \n",
    "\n",
    "## Constella groups: seeding vs. linking\n",
    "\n",
    "Now that we have covered the basics of how Constella detects groups it is worth taking a moment to discuss how Constella assigns names.  There are generally two strategies which largely are based on if prior encounters with plms that are being grouped through image series/time series data has occurred.  When we first began this notebook we assigned the variable 'group_iter' to 1 which serves as our counter variable for assigning serial numbers to each homology group as Constella detects them.  When a novel group is detected, be it a duet, graded pair in a quartet, or rogue plms Constella 'seeds' these groups by assigning them the current group_iter number and iterating the counter by one.  By contrast, some groups should be expected to appear for several images in a row, especially in time series data, and in these cases an identity is already established for one of the current pair.  In these cases 'linking' occurs in which the known identity for one of the pair is passed on to the yet to be defined member so that the identity of this group is allowed to be carried through time or across an image series of analogous data. \n",
    "\n",
    "Given this naming strategy of assigning numbers as identities it is probably worth noting that although Constella is designed for use in homology-based approaches it operates in an analogous sphere to de novo genome assemblers in that although both can identify probable relationships (either as genomic scaffolds or plm linkage groups) it makes no attempt to assign known identity to these groups akin to changing scaffold identities to that of known chromosomes for a given genome.  This step of defining plm groups as a specific leaf tip, a leaf axil/ligule, or a floral structure such as an inflorescence apex is a post analysis step to be undertaken by an end user.\n",
    "\n",
    "#### Where we left off...\n",
    "\n",
    "Now that we have a thorough understanding of exactly what we did by running running Constella it would probably be good to see how well it did wouldn't it? Let's have a look!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed9d701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>plmname</th>\n",
       "      <th>filename</th>\n",
       "      <th>plm_x</th>\n",
       "      <th>plm_y</th>\n",
       "      <th>SS_x</th>\n",
       "      <th>SS_y</th>\n",
       "      <th>TS_x</th>\n",
       "      <th>TS_y</th>\n",
       "      <th>CC_ratio</th>\n",
       "      <th>bot_left_dist</th>\n",
       "      <th>bot_right_dist</th>\n",
       "      <th>top_left_dist</th>\n",
       "      <th>top_right_dist</th>\n",
       "      <th>centroid_dist</th>\n",
       "      <th>orientation</th>\n",
       "      <th>centroid_orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>B100_rep1_d10_plm1</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>901</td>\n",
       "      <td>1151</td>\n",
       "      <td>892</td>\n",
       "      <td>1173</td>\n",
       "      <td>885</td>\n",
       "      <td>1167</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>521.647390</td>\n",
       "      <td>404.545424</td>\n",
       "      <td>331.185748</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>284.613773</td>\n",
       "      <td>-146.659293</td>\n",
       "      <td>155.506063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>B100_rep1_d10_plm2</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>787</td>\n",
       "      <td>1425</td>\n",
       "      <td>789</td>\n",
       "      <td>1401</td>\n",
       "      <td>773</td>\n",
       "      <td>1405</td>\n",
       "      <td>6.219512</td>\n",
       "      <td>252.103153</td>\n",
       "      <td>187.416648</td>\n",
       "      <td>371.295031</td>\n",
       "      <td>330.800544</td>\n",
       "      <td>15.524175</td>\n",
       "      <td>-15.255119</td>\n",
       "      <td>14.931417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>B100_rep1_d10_plm3</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>571</td>\n",
       "      <td>1344</td>\n",
       "      <td>594</td>\n",
       "      <td>1338</td>\n",
       "      <td>595</td>\n",
       "      <td>1342</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>409.538765</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>414.779459</td>\n",
       "      <td>222.036033</td>\n",
       "      <td>99.659893</td>\n",
       "      <td>-72.707551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>B100_rep1_d10_plm4</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>793</td>\n",
       "      <td>1523</td>\n",
       "      <td>796</td>\n",
       "      <td>1511</td>\n",
       "      <td>783</td>\n",
       "      <td>1519</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>224.294449</td>\n",
       "      <td>132.909744</td>\n",
       "      <td>457.475682</td>\n",
       "      <td>420.286807</td>\n",
       "      <td>113.441615</td>\n",
       "      <td>-23.629378</td>\n",
       "      <td>5.057249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>B100_rep1_d10_plm5</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>712</td>\n",
       "      <td>1511</td>\n",
       "      <td>736</td>\n",
       "      <td>1508</td>\n",
       "      <td>736</td>\n",
       "      <td>1512</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>147.705789</td>\n",
       "      <td>214.560015</td>\n",
       "      <td>412.825629</td>\n",
       "      <td>441.184769</td>\n",
       "      <td>123.458495</td>\n",
       "      <td>92.385944</td>\n",
       "      <td>-144.893921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>B100_rep1_d10_plm6</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>803</td>\n",
       "      <td>1555</td>\n",
       "      <td>795</td>\n",
       "      <td>1533</td>\n",
       "      <td>807</td>\n",
       "      <td>1532</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>490.354973</td>\n",
       "      <td>448.090393</td>\n",
       "      <td>146.372812</td>\n",
       "      <td>-5.079608</td>\n",
       "      <td>7.853313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>B100_rep1_d10_plm7</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>922</td>\n",
       "      <td>1415</td>\n",
       "      <td>898</td>\n",
       "      <td>1420</td>\n",
       "      <td>898</td>\n",
       "      <td>1416</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>377.890196</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>456.579675</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>139.089899</td>\n",
       "      <td>-97.125016</td>\n",
       "      <td>87.939889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>B100_rep1_d10_plm8</td>\n",
       "      <td>B100_rep1_d10</td>\n",
       "      <td>803</td>\n",
       "      <td>1478</td>\n",
       "      <td>816</td>\n",
       "      <td>1459</td>\n",
       "      <td>801</td>\n",
       "      <td>1454</td>\n",
       "      <td>12.207447</td>\n",
       "      <td>244.444268</td>\n",
       "      <td>141.739197</td>\n",
       "      <td>424.086076</td>\n",
       "      <td>374.414209</td>\n",
       "      <td>70.880181</td>\n",
       "      <td>165.650668</td>\n",
       "      <td>16.389540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>B100_rep1_d11_plm1</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>912</td>\n",
       "      <td>1123</td>\n",
       "      <td>904</td>\n",
       "      <td>1146</td>\n",
       "      <td>895</td>\n",
       "      <td>1139</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>550.368059</td>\n",
       "      <td>432.115725</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>314.658545</td>\n",
       "      <td>-147.339087</td>\n",
       "      <td>155.797162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>B100_rep1_d11_plm2</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>786</td>\n",
       "      <td>1370</td>\n",
       "      <td>794</td>\n",
       "      <td>1347</td>\n",
       "      <td>784</td>\n",
       "      <td>1346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.637092</td>\n",
       "      <td>229.610540</td>\n",
       "      <td>327.466029</td>\n",
       "      <td>281.966310</td>\n",
       "      <td>40.112342</td>\n",
       "      <td>172.724995</td>\n",
       "      <td>175.710847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>B100_rep1_d11_plm3</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>752</td>\n",
       "      <td>1236</td>\n",
       "      <td>761</td>\n",
       "      <td>1258</td>\n",
       "      <td>754</td>\n",
       "      <td>1260</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>366.772409</td>\n",
       "      <td>361.470607</td>\n",
       "      <td>213.377600</td>\n",
       "      <td>204.129861</td>\n",
       "      <td>176.739922</td>\n",
       "      <td>13.448615</td>\n",
       "      <td>-10.101876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>B100_rep1_d11_plm4</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>783</td>\n",
       "      <td>1427</td>\n",
       "      <td>781</td>\n",
       "      <td>1403</td>\n",
       "      <td>770</td>\n",
       "      <td>1406</td>\n",
       "      <td>32.692308</td>\n",
       "      <td>247.644907</td>\n",
       "      <td>188.957667</td>\n",
       "      <td>370.621100</td>\n",
       "      <td>334.270848</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-18.434949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>B100_rep1_d11_plm5</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>576</td>\n",
       "      <td>1353</td>\n",
       "      <td>598</td>\n",
       "      <td>1342</td>\n",
       "      <td>599</td>\n",
       "      <td>1347</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>202.061872</td>\n",
       "      <td>400.649473</td>\n",
       "      <td>230.054341</td>\n",
       "      <td>415.470817</td>\n",
       "      <td>214.704448</td>\n",
       "      <td>110.695451</td>\n",
       "      <td>-74.604451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>B100_rep1_d11_plm6</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>790</td>\n",
       "      <td>1525</td>\n",
       "      <td>791</td>\n",
       "      <td>1509</td>\n",
       "      <td>780</td>\n",
       "      <td>1517</td>\n",
       "      <td>23.448276</td>\n",
       "      <td>221.045244</td>\n",
       "      <td>135.366170</td>\n",
       "      <td>457.782700</td>\n",
       "      <td>423.117005</td>\n",
       "      <td>115.212847</td>\n",
       "      <td>-20.556045</td>\n",
       "      <td>3.483271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>B100_rep1_d11_plm7</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>706</td>\n",
       "      <td>1510</td>\n",
       "      <td>729</td>\n",
       "      <td>1505</td>\n",
       "      <td>730</td>\n",
       "      <td>1509</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>142.302495</td>\n",
       "      <td>220.637712</td>\n",
       "      <td>409.870711</td>\n",
       "      <td>443.198601</td>\n",
       "      <td>126.210142</td>\n",
       "      <td>97.275005</td>\n",
       "      <td>-142.403729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>B100_rep1_d11_plm8</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>802</td>\n",
       "      <td>1553</td>\n",
       "      <td>791</td>\n",
       "      <td>1532</td>\n",
       "      <td>801</td>\n",
       "      <td>1530</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>231.008658</td>\n",
       "      <td>120.016666</td>\n",
       "      <td>488.119862</td>\n",
       "      <td>446.430286</td>\n",
       "      <td>144.256716</td>\n",
       "      <td>-15.255119</td>\n",
       "      <td>7.568397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>B100_rep1_d11_plm9</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>914</td>\n",
       "      <td>1417</td>\n",
       "      <td>891</td>\n",
       "      <td>1423</td>\n",
       "      <td>890</td>\n",
       "      <td>1417</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>369.720164</td>\n",
       "      <td>138.231690</td>\n",
       "      <td>451.757678</td>\n",
       "      <td>294.108823</td>\n",
       "      <td>131.186890</td>\n",
       "      <td>-97.275005</td>\n",
       "      <td>86.941302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>B100_rep1_d11_plm10</td>\n",
       "      <td>B100_rep1_d11</td>\n",
       "      <td>798</td>\n",
       "      <td>1475</td>\n",
       "      <td>809</td>\n",
       "      <td>1464</td>\n",
       "      <td>795</td>\n",
       "      <td>1458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.684441</td>\n",
       "      <td>147.566934</td>\n",
       "      <td>418.847228</td>\n",
       "      <td>373.202358</td>\n",
       "      <td>66.708320</td>\n",
       "      <td>164.054604</td>\n",
       "      <td>12.994617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group              plmname       filename  plm_x  plm_y  SS_x  SS_y  TS_x  \\\n",
       "0      8   B100_rep1_d10_plm1  B100_rep1_d10    901   1151   892  1173   885   \n",
       "1      7   B100_rep1_d10_plm2  B100_rep1_d10    787   1425   789  1401   773   \n",
       "2      6   B100_rep1_d10_plm3  B100_rep1_d10    571   1344   594  1338   595   \n",
       "3      2   B100_rep1_d10_plm4  B100_rep1_d10    793   1523   796  1511   783   \n",
       "4      3   B100_rep1_d10_plm5  B100_rep1_d10    712   1511   736  1508   736   \n",
       "5      1   B100_rep1_d10_plm6  B100_rep1_d10    803   1555   795  1533   807   \n",
       "6      5   B100_rep1_d10_plm7  B100_rep1_d10    922   1415   898  1420   898   \n",
       "7      4   B100_rep1_d10_plm8  B100_rep1_d10    803   1478   816  1459   801   \n",
       "8      8   B100_rep1_d11_plm1  B100_rep1_d11    912   1123   904  1146   895   \n",
       "9      9   B100_rep1_d11_plm2  B100_rep1_d11    786   1370   794  1347   784   \n",
       "10    10   B100_rep1_d11_plm3  B100_rep1_d11    752   1236   761  1258   754   \n",
       "11     7   B100_rep1_d11_plm4  B100_rep1_d11    783   1427   781  1403   770   \n",
       "12     6   B100_rep1_d11_plm5  B100_rep1_d11    576   1353   598  1342   599   \n",
       "13     2   B100_rep1_d11_plm6  B100_rep1_d11    790   1525   791  1509   780   \n",
       "14     3   B100_rep1_d11_plm7  B100_rep1_d11    706   1510   729  1505   730   \n",
       "15     1   B100_rep1_d11_plm8  B100_rep1_d11    802   1553   791  1532   801   \n",
       "16     5   B100_rep1_d11_plm9  B100_rep1_d11    914   1417   891  1423   890   \n",
       "17     4  B100_rep1_d11_plm10  B100_rep1_d11    798   1475   809  1464   795   \n",
       "\n",
       "    TS_y    CC_ratio  bot_left_dist  bot_right_dist  top_left_dist  \\\n",
       "0   1167  255.000000     521.647390      404.545424     331.185748   \n",
       "1   1405    6.219512     252.103153      187.416648     371.295031   \n",
       "2   1342  255.000000     211.000000      409.538765     221.000000   \n",
       "3   1519   18.888889     224.294449      132.909744     457.475682   \n",
       "4   1512  255.000000     147.705789      214.560015     412.825629   \n",
       "5   1532  255.000000     232.000000      119.000000     490.354973   \n",
       "6   1416  255.000000     377.890196      140.000000     456.579675   \n",
       "7   1454   12.207447     244.444268      141.739197     424.086076   \n",
       "8   1139  255.000000     550.368059      432.115725     341.000000   \n",
       "9   1346    0.000000     283.637092      229.610540     327.466029   \n",
       "10  1260  255.000000     366.772409      361.470607     213.377600   \n",
       "11  1406   32.692308     247.644907      188.957667     370.621100   \n",
       "12  1347  255.000000     202.061872      400.649473     230.054341   \n",
       "13  1517   23.448276     221.045244      135.366170     457.782700   \n",
       "14  1509  255.000000     142.302495      220.637712     409.870711   \n",
       "15  1530  255.000000     231.008658      120.016666     488.119862   \n",
       "16  1417  255.000000     369.720164      138.231690     451.757678   \n",
       "17  1458    0.000000     240.684441      147.566934     418.847228   \n",
       "\n",
       "    top_right_dist  centroid_dist  orientation  centroid_orientation  \n",
       "0        35.000000     284.613773  -146.659293            155.506063  \n",
       "1       330.800544      15.524175   -15.255119             14.931417  \n",
       "2       414.779459     222.036033    99.659893            -72.707551  \n",
       "3       420.286807     113.441615   -23.629378              5.057249  \n",
       "4       441.184769     123.458495    92.385944           -144.893921  \n",
       "5       448.090393     146.372812    -5.079608              7.853313  \n",
       "6       292.000000     139.089899   -97.125016             87.939889  \n",
       "7       374.414209      70.880181   165.650668             16.389540  \n",
       "8        10.000000     314.658545  -147.339087            155.797162  \n",
       "9       281.966310      40.112342   172.724995            175.710847  \n",
       "10      204.129861     176.739922    13.448615            -10.101876  \n",
       "11      334.270848      17.000000   -18.434949              0.000000  \n",
       "12      415.470817     214.704448   110.695451            -74.604451  \n",
       "13      423.117005     115.212847   -20.556045              3.483271  \n",
       "14      443.198601     126.210142    97.275005           -142.403729  \n",
       "15      446.430286     144.256716   -15.255119              7.568397  \n",
       "16      294.108823     131.186890   -97.275005             86.941302  \n",
       "17      373.202358      66.708320   164.054604             12.994617  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_plms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d7e3a",
   "metadata": {},
   "source": [
    "It definitely appears as if we have paired groups between the majority of our plms across days 10 and 11! The only exceptions appear to be two plms specific to day 11 which are assigned to groups 9 and 10.  It would probably be worth seeing how these stack up on our original data (i.e. the images) since these data tables are often aren't the easiest to process.  With that being said, let's superimpose these groups onto the plms coordinates on each frame to see if they are in agreement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3355adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf8a1e85a614616a2099468136dac5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7efc3f40f94ad9b80a5bde22221168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6609ea9c49a4fd189831606f3cb43d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1, _, _ = pcv.readimage(filename=os.path.join(path, f\"{name_prefix}{day}.jpg\"))\n",
    "\n",
    "for p in range(0, cur_plms.shape[0]):\n",
    "    if f\"{name_prefix}{day}\" in cur_plms.at[p, 'plmname']:        \n",
    "        cv2.putText(img1, str(cur_plms.at[p, 'group']), \n",
    "                    (int(cur_plms.at[p, 'plm_x'])-10, int(cur_plms.at[p, 'plm_y'])), \n",
    "                    cv2.FONT_ITALIC, 1.5, (255,0,0), 6)\n",
    "\n",
    "img2, _, _ = pcv.readimage(filename=os.path.join(path, f\"{name_prefix}{day + 1}.jpg\"))\n",
    "\n",
    "for p in range(0, cur_plms.shape[0]):\n",
    "    if f\"{name_prefix}{day + 1}\" in cur_plms.at[p, 'plmname']:        \n",
    "        cv2.putText(img2, str(cur_plms.at[p, 'group']), \n",
    "                    (int(cur_plms.at[p, 'plm_x'])-10, int(cur_plms.at[p, 'plm_y'])), \n",
    "                    cv2.FONT_ITALIC, 1.5, (0,0,255), 6)\n",
    "  \n",
    "img_neighbors = cv2.hconcat((img1, img2))\n",
    "\n",
    "plm_groups_fig=plt.figure(figsize=(8, 6))\n",
    "plm_groups_fig=plt.imshow(img_neighbors)\n",
    "plm_groups_fig=plt.xscale('linear')\n",
    "plm_groups_fig=plt.axis('off')\n",
    "plm_groups_fig=plt.title(f'B100 day {day}-{day + 1}')\n",
    "plt.show(plm_groups_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e325a7d2",
   "metadata": {},
   "source": [
    "Looking at our groups overlaid against the leaf tips and ligules it seems like our attempts at forming homology groups through our workflow was a success! And note how our ligule and leaf tip plms corresponding to the emergent leaf in day 11 are represented by groups '9' and '10' which didn't appear in our first frame, seeding new groups as novel structures appear is clearly working as advertised as well! \n",
    "\n",
    "Now that we understand how homology grouping works through the use of our Space >>> StarScape >>> Constella workflow we will use our final exercise to expand on what we've learned and apply it to store time series data and utilize groundtruthed plms of QC steps during pipeline development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa73fb-5626-436d-a302-4f7848c8e2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:plantcv] *",
   "language": "python",
   "name": "conda-env-plantcv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
